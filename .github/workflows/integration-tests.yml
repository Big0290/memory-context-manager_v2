name: Memory Context Manager v2 - Complete Integration Tests

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
      fail-fast: false
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache Python Dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install System Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y sqlite3 libsqlite3-dev
        
    - name: Install Python Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install pytest pytest-asyncio pytest-cov psutil
        
    - name: Create Test Database Directory
      run: |
        mkdir -p brain_memory_store
        
    - name: Initialize Test Environment
      run: |
        # Copy test database if exists, otherwise create minimal structure
        if [ -f "brain_memory_store/brain.db.test" ]; then
          cp brain_memory_store/brain.db.test brain_memory_store/brain.db
        else
          python3 -c "
          import sqlite3
          import os
          os.makedirs('brain_memory_store', exist_ok=True)
          with sqlite3.connect('brain_memory_store/brain.db') as conn:
            # Create minimal required tables for testing
            conn.execute('CREATE TABLE IF NOT EXISTS memory_store (key TEXT PRIMARY KEY, value TEXT, timestamp TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS brain_state (key TEXT PRIMARY KEY, value TEXT, updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS function_calls (id INTEGER PRIMARY KEY AUTOINCREMENT, session_id TEXT, timestamp TEXT, function_name TEXT, function_type TEXT, success BOOLEAN DEFAULT 1, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS dream_system_metrics (id INTEGER PRIMARY KEY, dream_cycles INTEGER DEFAULT 1, cross_references_processed INTEGER DEFAULT 10, relationships_enhanced INTEGER DEFAULT 5, context_injections_generated INTEGER DEFAULT 15, knowledge_synthesis_events INTEGER DEFAULT 8, memory_consolidation_cycles INTEGER DEFAULT 3, last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS learning_bits (id INTEGER PRIMARY KEY, content TEXT, content_type TEXT, category TEXT, importance_score REAL DEFAULT 0.5, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS cross_references (id INTEGER PRIMARY KEY, source_bit_id INTEGER, target_bit_id INTEGER, relationship_type TEXT DEFAULT \"related\", strength REAL DEFAULT 1.0, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS context_enhancement_pipeline (id INTEGER PRIMARY KEY, trigger_type TEXT, enhancement_type TEXT, status TEXT DEFAULT \"completed\", created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS identity_profiles (id TEXT PRIMARY KEY, name TEXT, profile_data TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS memory_chunks (id TEXT PRIMARY KEY, content TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            conn.execute('CREATE TABLE IF NOT EXISTS conversation_memories (id INTEGER PRIMARY KEY, content TEXT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)')
            # Insert test data
            conn.execute('INSERT OR IGNORE INTO dream_system_metrics (dream_cycles, cross_references_processed, relationships_enhanced, context_injections_generated, knowledge_synthesis_events, memory_consolidation_cycles) VALUES (3, 30, 15, 25, 12, 8)')
            conn.execute('INSERT OR IGNORE INTO memory_store (key, value, timestamp) VALUES (\"test_memory\", \"test_value\", \"2024-01-01T00:00:00\")')
            conn.execute('INSERT OR IGNORE INTO function_calls (function_name, function_type, success) VALUES (\"test_function\", \"test_type\", 1)')
            conn.execute('INSERT OR IGNORE INTO learning_bits (content, content_type, category, importance_score) VALUES (\"test_learning\", \"concept\", \"testing\", 0.8)')
            conn.execute('INSERT OR IGNORE INTO cross_references (source_bit_id, target_bit_id, relationship_type, strength) VALUES (1, 1, \"related\", 1.0)')
            conn.execute('INSERT OR IGNORE INTO context_enhancement_pipeline (trigger_type, enhancement_type) VALUES (\"test_trigger\", \"test_enhancement\")')
            conn.commit()
          print('âœ… Test database initialized')
          "
        fi
        
    - name: Run Complete Integration Test Suite
      run: |
        echo "ğŸ§ª Running Memory Context Manager v2 Complete Integration Tests"
        python3 test_complete_integration.py --ci --verbose
        
    - name: Run Integration Tests with Pytest (Alternative)
      run: |
        # Run with pytest as backup validation
        python3 -m pytest test_complete_integration.py::IntegrationTestSuite::run_all_tests -v --tb=short || echo "Pytest backup completed"
        
    - name: Generate Test Report
      if: always()
      run: |
        echo "ğŸ“Š Generating Integration Test Report"
        python3 -c "
        import json
        import glob
        import os
        from datetime import datetime
        
        # Find latest test results file
        result_files = glob.glob('test_results_*.json')
        if result_files:
          latest_file = max(result_files, key=os.path.getctime)
          print(f'ğŸ“„ Latest test results: {latest_file}')
          
          with open(latest_file, 'r') as f:
            results = json.load(f)
          
          summary = results.get('summary', {})
          print(f'ğŸ“ˆ Test Summary:')
          print(f'  Overall Status: {summary.get(\"overall_status\", \"UNKNOWN\")}')
          print(f'  Grade: {summary.get(\"grade\", \"N/A\")}')
          print(f'  Success Rate: {summary.get(\"success_rate\", 0):.1%}')
          print(f'  Tests Passed: {summary.get(\"tests_passed\", 0)}/{summary.get(\"total_tests\", 0)}')
          
          # Create GitHub Actions summary
          with open('integration_test_summary.md', 'w') as f:
            f.write('# Memory Context Manager v2 - Integration Test Results\\n\\n')
            f.write(f'## Overall Status: {summary.get(\"overall_status\", \"UNKNOWN\")}\\n')
            f.write(f'**Grade:** {summary.get(\"grade\", \"N/A\")}\\n\\n')
            f.write(f'**Success Rate:** {summary.get(\"success_rate\", 0):.1%}\\n\\n')
            f.write(f'**Tests Passed:** {summary.get(\"tests_passed\", 0)}/{summary.get(\"total_tests\", 0)}\\n\\n')
            
            f.write('## Test Categories\\n\\n')
            for category in results.get('test_categories', []):
              status = 'âœ…' if category.get('passed') else 'âŒ'
              f.write(f'{status} **{category.get(\"category\", \"Unknown\")}**: {category.get(\"passed_tests\", 0)}/{category.get(\"total_tests\", 0)} passed\\n')
            
            f.write(f'\\n## Test Duration\\n{results.get(\"total_duration\", 0):.2f} seconds\\n')
        else:
          print('âš ï¸ No test results file found')
        "
        
    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-results-python-${{ matrix.python-version }}-${{ github.run_number }}
        path: |
          test_results_*.json
          integration_test_summary.md
        retention-days: 30
        if-no-files-found: warn
        
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          if (fs.existsSync('integration_test_summary.md')) {
            const testSummary = fs.readFileSync('integration_test_summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ğŸ§ª Integration Test Results (Python ${{ matrix.python-version }})
              
              ${testSummary}
              
              *Automated test run for commit ${context.sha.substring(0, 8)}*`
            });
          }

  security-scan:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Run Security Scan
      run: |
        echo "ğŸ”’ Running Security Scan"
        # Basic security checks
        find . -name "*.py" -type f -exec grep -l "password\|secret\|key\|token" {} \; | grep -v test || echo "No obvious secrets found"
        
        # Check for obvious security issues in database files
        if [ -f "brain_memory_store/brain.db" ]; then
          echo "âš ï¸ Warning: Database file present in repository"
        fi
        
    - name: Dependency Security Check
      run: |
        python -m pip install safety
        safety check --json || echo "Security check completed with warnings"

  performance-benchmark:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install psutil
        
    - name: Run Performance Benchmark
      run: |
        echo "âš¡ Running Performance Benchmark"
        python3 -c "
        import time
        import psutil
        import os
        from datetime import datetime
        
        print('ğŸ Memory Context Manager v2 - Performance Benchmark')
        print('=' * 60)
        
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # Test database operations
        if os.path.exists('brain_memory_store/brain.db'):
          import sqlite3
          with sqlite3.connect('brain_memory_store/brain.db') as conn:
            cursor = conn.cursor()
            
            # Benchmark database queries
            query_start = time.time()
            cursor.execute('SELECT COUNT(*) FROM memory_store')
            cursor.execute('SELECT COUNT(*) FROM function_calls')
            cursor.execute('SELECT COUNT(*) FROM learning_bits')
            query_time = time.time() - query_start
            
            print(f'ğŸ“Š Database Query Performance: {query_time:.3f}s')
        
        # Memory usage
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_delta = end_memory - start_memory
        
        total_time = time.time() - start_time
        
        print(f'â±ï¸  Total Benchmark Time: {total_time:.3f}s')
        print(f'ğŸ’¾ Memory Usage: {end_memory:.1f}MB (Î”{memory_delta:+.1f}MB)')
        
        # Performance thresholds
        if total_time > 5.0:
          print('âš ï¸  Performance warning: Benchmark took longer than expected')
        if end_memory > 200:
          print('âš ï¸  Memory warning: High memory usage detected')
          
        print('âœ… Performance benchmark completed')
        "

  notify-status:
    runs-on: ubuntu-latest
    needs: [integration-tests, security-scan, performance-benchmark]
    if: always()
    
    steps:
    - name: Notify Status
      run: |
        echo "ğŸ“¢ Integration Test Pipeline Status"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Security Scan: ${{ needs.security-scan.result }}"
        echo "Performance Benchmark: ${{ needs.performance-benchmark.result }}"
        
        if [[ "${{ needs.integration-tests.result }}" == "success" && "${{ needs.security-scan.result }}" == "success" && "${{ needs.performance-benchmark.result }}" == "success" ]]; then
          echo "ğŸ‰ All checks passed! System ready for deployment."
        else
          echo "âŒ Some checks failed. Review results before deploying."
        fi