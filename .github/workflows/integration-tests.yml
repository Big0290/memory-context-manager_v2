name: Memory Context Manager v2 - Complete Integration Tests

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']
      fail-fast: false
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache Python Dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install System Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y sqlite3 libsqlite3-dev
        
    - name: Install Python Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install pytest pytest-asyncio pytest-cov psutil
        
    - name: Create Test Database Directory
      run: |
        mkdir -p brain_memory_store
        
    - name: Initialize Test Environment
      run: |
        # Copy test database if exists, otherwise create minimal structure
        if [ -f "brain_memory_store/brain.db.test" ]; then
          cp brain_memory_store/brain.db.test brain_memory_store/brain.db
          echo "✅ Copied existing test database"
        else
          python3 scripts/init_test_database.py
        fi
        
    - name: Run Complete Integration Test Suite
      run: |
        echo "🧪 Running Memory Context Manager v2 Complete Integration Tests"
        python3 test_complete_integration.py --ci --verbose
        
    - name: Run Integration Tests with Pytest (Alternative)
      run: |
        # Run with pytest as backup validation
        python3 -m pytest test_complete_integration.py::IntegrationTestSuite::run_all_tests -v --tb=short || echo "Pytest backup completed"
        
    - name: Generate Test Report
      if: always()
      run: |
        echo "📊 Generating Integration Test Report"
        python3 scripts/generate_test_report.py
        
    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-results-python-${{ matrix.python-version }}-${{ github.run_number }}
        path: |
          test_results_*.json
          integration_test_summary.md
        retention-days: 30
        if-no-files-found: warn
        
    - name: Comment on PR (if applicable)
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          if (fs.existsSync('integration_test_summary.md')) {
            const testSummary = fs.readFileSync('integration_test_summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 🧪 Integration Test Results (Python ${{ matrix.python-version }})
              
              ${testSummary}
              
              *Automated test run for commit ${context.sha.substring(0, 8)}*`
            });
          }

  security-scan:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Run Security Scan
      run: |
        echo "🔒 Running Security Scan"
        # Basic security checks
        find . -name "*.py" -type f -exec grep -l "password\|secret\|key\|token" {} \; | grep -v test || echo "No obvious secrets found"
        
        # Check for obvious security issues in database files
        if [ -f "brain_memory_store/brain.db" ]; then
          echo "⚠️ Warning: Database file present in repository"
        fi
        
    - name: Dependency Security Check
      run: |
        python -m pip install safety
        safety check --json || echo "Security check completed with warnings"

  performance-benchmark:
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install psutil
        
    - name: Run Performance Benchmark
      run: |
        echo "⚡ Running Performance Benchmark"
        python3 -c "
        import time
        import psutil
        import os
        from datetime import datetime
        
        print('🏁 Memory Context Manager v2 - Performance Benchmark')
        print('=' * 60)
        
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        # Test database operations
        if os.path.exists('brain_memory_store/brain.db'):
          import sqlite3
          with sqlite3.connect('brain_memory_store/brain.db') as conn:
            cursor = conn.cursor()
            
            # Benchmark database queries
            query_start = time.time()
            cursor.execute('SELECT COUNT(*) FROM memory_store')
            cursor.execute('SELECT COUNT(*) FROM function_calls')
            cursor.execute('SELECT COUNT(*) FROM learning_bits')
            query_time = time.time() - query_start
            
            print(f'📊 Database Query Performance: {query_time:.3f}s')
        
        # Memory usage
        end_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_delta = end_memory - start_memory
        
        total_time = time.time() - start_time
        
        print(f'⏱️  Total Benchmark Time: {total_time:.3f}s')
        print(f'💾 Memory Usage: {end_memory:.1f}MB (Δ{memory_delta:+.1f}MB)')
        
        # Performance thresholds
        if total_time > 5.0:
          print('⚠️  Performance warning: Benchmark took longer than expected')
        if end_memory > 200:
          print('⚠️  Memory warning: High memory usage detected')
          
        print('✅ Performance benchmark completed')
        "

  notify-status:
    runs-on: ubuntu-latest
    needs: [integration-tests, security-scan, performance-benchmark]
    if: always()
    
    steps:
    - name: Notify Status
      run: |
        echo "📢 Integration Test Pipeline Status"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Security Scan: ${{ needs.security-scan.result }}"
        echo "Performance Benchmark: ${{ needs.performance-benchmark.result }}"
        
        if [[ "${{ needs.integration-tests.result }}" == "success" && "${{ needs.security-scan.result }}" == "success" && "${{ needs.performance-benchmark.result }}" == "success" ]]; then
          echo "🎉 All checks passed! System ready for deployment."
        else
          echo "❌ Some checks failed. Review results before deploying."
        fi